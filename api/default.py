# default.py
from dotenv import load_dotenv
import os

from langchain_teddynote import logging
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnablePassthrough

# API KEY Ï†ïÎ≥¥ Î°úÎìú
load_dotenv()
GEMINI_API_KEY = os.getenv('API_KEY_GEMINI')

# LangSmith Ï∂îÏ†Å ÏÑ§Ï†ï
logging.langsmith("lgdx_team2_routerchain")

# default_chain (ÏÇ¨Ïö©ÏûêÏùò ÏùòÎØ∏ÏóÜÎäî ÏûÖÎ†•Í∞íÏóê ÎåÄÌï¥ Ï†ïÌï¥ÏßÑ ÎãµÎ≥ÄÏùÑ Ìï† Îïå)
default_template = """
"You are a chatbot that must always respond with 'üê∂: Î©çÎ©ç!'.
No matter what question the user asks, always reply with 'üê∂: Î©çÎ©ç!'"

[ÏÇ¨Ïö©Ïûê ÏûÖÎ†•]:
{user_input}
[Î∂ÑÎ•ò Í≤∞Í≥º]:
{classification_result}
"""
default_prompt = ChatPromptTemplate.from_template(default_template)

# Google Gemini Î™®Îç∏ ÏÉùÏÑ±
def load_gemini():
    model = ChatGoogleGenerativeAI(
        model='gemini-1.5-flash',
        temperature=0,
        max_tokens=500,
        api_key=GEMINI_API_KEY
    )
    print(">>>>>>> model loaded from default chain...")
    return model

default_llm = load_gemini()

# langchain Ï≤¥Ïù∏ Íµ¨ÏÑ±
default_chain = (
  {"classification_result": RunnablePassthrough(),
   "user_input": RunnablePassthrough()}
  | default_prompt
  | default_llm
  | StrOutputParser()
)
