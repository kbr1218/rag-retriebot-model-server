{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM ModelTest #2\n",
    "#### *ibm-granite/granite-embedding-278m-multilingual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('API_KEY_GEMINI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "dx_project\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"dx_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "# ë­ì²´ì¸ í™˜ê²½ ì„¤ì •\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "#from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ìˆ˜: 3901\n"
     ]
    }
   ],
   "source": [
    "### 01. CSV íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ ###\n",
    "loader = CSVLoader('../data/movie_4000_preprocessed.csv', encoding='utf8')\n",
    "docs = loader.load()\n",
    "print(f\"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}\")\n",
    "\n",
    "### 02. pandasë¡œ ë°ì´í„°í”„ë ˆì„ ì¹¼ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°\n",
    "csv_path = '../data/movie_4000_preprocessed.csv'\n",
    "df = pd.read_csv(csv_path, encoding='utf8')\n",
    "colnames = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì˜ ìˆ˜: 3901\n",
      "[ë©”íƒ€ë°ì´í„° ì˜ˆì‹œ]\n",
      " {'title': 'ì•„ë¦„ë‹µë‹¤', 'genre': 'ë“œë¼ë§ˆ'}\n"
     ]
    }
   ],
   "source": [
    "### 03. ë©”íƒ€ë°ì´í„° ì¶”ê°€ ###\n",
    "docs = []\n",
    "for _, row in df.iterrows():\n",
    "  # í•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì„¤ì •\n",
    "  metadata = {\n",
    "    'title': row['movie_title'],\n",
    "    'genre': row['genre']\n",
    "  }\n",
    "  # ê° í–‰ì˜ ë°ì´í„°ë¥¼ ë¬¸ì„œë¡œ ë³€í™˜\n",
    "  doc = Document(\n",
    "    page_content=str(row.to_dict()),\n",
    "    metadata=metadata\n",
    "  )\n",
    "  docs.append(doc)\n",
    "\n",
    "print(f\"ë¬¸ì„œì˜ ìˆ˜: {len(docs)}\")\n",
    "print('[ë©”íƒ€ë°ì´í„° ì˜ˆì‹œ]\\n', docs[100].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitëœ ë¬¸ì„œì˜ ìˆ˜: 3901\n"
     ]
    }
   ],
   "source": [
    "### 04. ë°ì´í„° ì²­í¬ ë‚˜ëˆ„ê¸° ###\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1090, chunk_overlap=0\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"splitëœ ë¬¸ì„œì˜ ìˆ˜:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15068\\3636801640.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='ibm-granite/granite-embedding-278m-multilingual')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365785b9602941c69a2c592192ca25b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd5fadd2174b47ae65afba0af571c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/610k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f77b054b0e46ea9b16053788558b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad7c4f0fb5344498e73aabd69602ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b28a559fb4611950907f15fa00210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/556M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee78d2141b04eddb1efc6fd4e7347de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe38b27bb58a47e5aa9215d3fec35809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3555902333024593bc1ece88559cc5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64833d35573436294c6aab1fc7abffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspaces\\proj\\forllm\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a471d5e4384572843ae36fe56e7d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 05. ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "# https://huggingface.co/ibm-granite/granite-embedding-278m-multilingual\n",
    "embeddings = HuggingFaceEmbeddings(model_name='ibm-granite/granite-embedding-278m-multilingual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15068\\1735004291.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"../data/movie_4000_vectorstore_2\", embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "# Chroma ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
    "vectorstore = Chroma(persist_directory=\"../data/movie_4000_vectorstore_2\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì‚¬ìš©ì ì…ë ¥ê°’ ìœ í˜• ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸\n",
    "classification_template = \"\"\"ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë‹¤ìŒ ì„¸ ê°€ì§€ ë²”ì£¼ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:\n",
    "1ï¸âƒ£ **\"ì •ë³´ê²€ìƒ‰\"**: íŠ¹ì • ì˜í™”, ë“œë¼ë§ˆ, ë°°ìš°, ê°ë…, ëŸ¬ë‹íƒ€ì„, ê°œë´‰ ì—°ë„, ìˆ˜ìƒ ë‚´ì—­, í•„ëª¨ê·¸ë˜í”¼ ë“± **ì‚¬ì‹¤ì ì¸ ì •ë³´ë¥¼ ì°¾ëŠ” ì§ˆë¬¸**\n",
    "   - ê¸°ëŒ€ë˜ëŠ” ì‘ë‹µ ì˜ˆì‹œ: ë°°ìš°ê°€ ì¶œì—°í•œ ë“œë¼ë§ˆ/ì˜í™” ëª©ë¡, íŠ¹ì • ì—°ë„ì˜ ê°œë´‰ì‘ ë¦¬ìŠ¤íŠ¸ ë“±\n",
    "2ï¸âƒ£ **\"ì¶”ì²œìš”ì²­\"**: íŠ¹ì • ì¥ë¥´, ë°°ìš°, í…Œë§ˆ(ì˜ˆ: ì¢€ë¹„, ì‹œê°„ì—¬í–‰), ê°ì„±(ì˜ˆ: íë§, ê¸´ì¥ê°) ë“±ì— ëŒ€í•œ **ì¶”ì²œì„ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸**\n",
    "   - ê¸°ëŒ€ë˜ëŠ” ì‘ë‹µ ì˜ˆì‹œ: íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì˜í™”/ë“œë¼ë§ˆ ì¶”ì²œ\n",
    "3ï¸âƒ£ **\"ì¼ë°˜ëŒ€í™”\"**: ì„œë¹„ìŠ¤ì™€ ë¬´ê´€í•œ ì¼ë°˜ì ì¸ ëŒ€í™” (ì˜ˆ: ë‚ ì”¨, AI ê´€ë ¨ ì§ˆë¬¸, ì¡ë‹´)\n",
    "\n",
    "ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ë°˜í™˜í•˜ì„¸ìš”.\n",
    "\n",
    "#### **ì˜ˆì‹œ í˜•ì‹**\n",
    "{{\n",
    "  \"type\": \"ì •ë³´ê²€ìƒ‰\",\n",
    "  \"keywords\": [\"í•œíš¨ì£¼\", \"ë“œë¼ë§ˆ\", \"ì¶œì—°\"]\n",
    "}}\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(classification_template)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain ì²´ì¸ êµ¬ì„±\n",
    "classification_chain = (\n",
    "  prompt\n",
    "  | llm\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"ì •ë³´ê²€ìƒ‰\",\n",
      "  \"keywords\": [\"í•œíš¨ì£¼\", \"ë“œë¼ë§ˆ\", \"ì¶œì—°\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"ì¶”ì²œìš”ì²­\",\n",
      "  \"keywords\": [\"ìŠ¤íŒŒì´ë”ë§¨\", \"ì˜í™”\", \"ì¶”ì²œ\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"ì¶”ì²œìš”ì²­\",\n",
      "  \"keywords\": [\"ì½”ë¯¸ë””\", \"í˜¸ëŸ¬\", \"ì˜í™”\", \"ì¶”ì²œ\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"ì¼ë°˜ëŒ€í™”\",\n",
      "  \"keywords\": [\"ì‹¬ì‹¬í•´\"]\n",
      "}\n",
      "{\n",
      "  \"type\": \"ì¼ë°˜ëŒ€í™”\",\n",
      "  \"keywords\": [\"ìš°ìš¸\", \"ê°ì •\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆìƒ ì •ë³´ê²€ìƒ‰\n",
    "print(classification_chain.invoke({\"question\": \"í•œíš¨ì£¼ê°€ ë‚˜ì˜¤ëŠ” ë“œë¼ë§ˆ ì•Œë ¤ì¤˜.\"}))\n",
    "print(classification_chain.invoke({\"question\": \"ìŠ¤íŒŒì´ë”ë§¨ ì˜í™”ë¥¼ ë³´ê³ ì‹¶ì–´\"}))\n",
    "\n",
    "# ì¶”ì²œ ìš”ì²­\n",
    "print(classification_chain.invoke({\"question\": \"ì½”ë¯¸ë””ë©´ì„œ í˜¸ëŸ¬ ì¥ë¥´ì˜ ì˜í™”ë¥¼ ì¶”ì²œí•´ì¤˜\"}))\n",
    "\n",
    "# ì¼ë°˜ëŒ€í™”í™”\n",
    "print(classification_chain.invoke({\"question\": \"ì‹¬ì‹¬í•´\"}))\n",
    "print(classification_chain.invoke({\"question\": \"ì˜¤ëŠ˜ì€ ìš°ìš¸í•œê±¸\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON ê²°ê³¼ë¥¼ ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜\n",
    "def preprocess_classification_result(question: str):\n",
    "    classification_result = classification_chain.invoke({\"question\": question})\n",
    "\n",
    "    # JSON ë¬¸ìì—´ì—ì„œ ```json``` ì œê±° (ì •ê·œì‹ í™œìš©)\n",
    "    json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', classification_result, re.DOTALL)\n",
    "    if json_match:\n",
    "        clean_json_str = json_match.group(1)                       # ì¤‘ê´„í˜¸ {} ë‚´ë¶€ë§Œ ì¶”ì¶œ\n",
    "    else:\n",
    "        clean_json_str = classification_result                     # ```json``` íƒœê·¸ê°€ ì—†ì„ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "    # JSON ë¬¸ìì—´ì„ dict ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜\n",
    "    try:\n",
    "        classification_data = json.loads(clean_json_str)\n",
    "        type_value = classification_data.get(\"type\", \"ì¼ë°˜ëŒ€í™”\")   # ê¸°ë³¸ê°’ì„ 'ì¼ë°˜ëŒ€í™”'ë¡œ ì„¤ì •\n",
    "        keywords = classification_data.get(\"keywords\", [])         # ê¸°ë³¸ê°’ì„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âš ï¸ JSONDecodeError: {e}\")  # JSON ë³€í™˜ ì˜¤ë¥˜ í™•ì¸\n",
    "        type_value = \"ì¼ë°˜ëŒ€í™”\"           # JSON ë³€í™˜ ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì„¤ì •\n",
    "        keywords = []\n",
    "    \n",
    "    return {\"type\": type_value, \"keywords\": keywords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_chain ìƒì„± (ì‚¬ìš©ìì˜ ì˜ë¯¸ì—†ëŠ” ì…ë ¥ê°’ì— ëŒ€í•´ ì •í•´ì§„ ë‹µë³€ì„ í•  ë•Œ)\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "default_template = \"\"\"\n",
    "\"You are a chatbot that must always respond with 'ğŸ¶: ë©ë©!'.\n",
    "No matter what question the user asks, always reply with 'ğŸ¶: ë©ë©!'\"\n",
    "\n",
    "[ì‚¬ìš©ì ì…ë ¥ê³¼ ë¶„ë¥˜ ê²°ê³¼]:\n",
    "{classification_result}\n",
    "\"\"\"\n",
    "default_prompt = ChatPromptTemplate.from_template(default_template)\n",
    "\n",
    "default_llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0)\n",
    "\n",
    "# langchain ì²´ì¸ êµ¬ì„±\n",
    "default_chain = (\n",
    "  {\"classification_result\": RunnablePassthrough()}\n",
    "  | default_prompt               # í•˜ë‚˜ë¡œ ë§Œë“  ë¬¸ì„œë¥¼ promptì— ë„˜ê²¨ì£¼ê³ \n",
    "  | default_llm            # llmì´ ì›í•˜ëŠ” ë‹µë³€ì„ ë§Œë“¦\n",
    "  | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# langchain router\n",
    "##  ì •ë³´ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ê¸° ìƒì„±\n",
    "# mmr ì¤‘ë³µ í”¼í•˜ê¸°, ë¬¸ì„œì˜ê´€ë ¨ì„±ê³¼ ì°¨ë³„ì„± ê³ ë ¤, \n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",   \n",
    "    search_kwargs={\"k\": 20,              # ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (default: 4)\n",
    "                   \"fetch_k\": 50,       # MMR ì•Œê³ ë¦¬ì¦˜ì— ì „ë‹¬í•  ë¬¸ì„œ ìˆ˜\n",
    "                   \"lambda_mult\": 0.5,    # ê²°ê³¼ ë‹¤ì–‘ì„± ì¡°ì ˆ (default: 0.5),\n",
    "                   }\n",
    ")\n",
    "\n",
    "info_template = \"\"\"\n",
    "ì‚¬ìš©ìê°€ ì˜í™”ë‚˜ ë“œë¼ë§ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ **ê°€ì¥ ì ì ˆí•œ ë¬¸ì„œ(ì»¨í…ì¸ )ë¥¼ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰**í•œ í›„, \n",
    "í•´ë‹¹ ì •ë³´ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "### **ì˜ˆì‹œ ì‘ë‹µ í˜•ì‹**\n",
    "{{\n",
    "  \"title\": \"ì¸ì…‰ì…˜\",\n",
    "  \"genre\": [\"SF\", \"ìŠ¤ë¦´ëŸ¬\"]\n",
    "}}\n",
    "\n",
    "[ì‚¬ìš©ì ì…ë ¥ê³¼ ë¶„ë¥˜ ê²°ê³¼]:\n",
    "{classification_result}\n",
    "\n",
    "[Context]: \n",
    "{retrieved_context} \n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "info_prompt = ChatPromptTemplate.from_template(info_template)\n",
    "info_chain = (\n",
    "    {\n",
    "      \"classification_result\": RunnablePassthrough(),\n",
    "      \"retrieved_context\": retriever\n",
    "    }\n",
    "    |info_prompt\n",
    "    |llm\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í…Œë””"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    # ì£¼ì œì— \"ì •ë³´ê²€ìƒ‰\"ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°\n",
    "    if \"ì •ë³´ê²€ìƒ‰\" in info[\"topic\"].lower():\n",
    "        return info_chain\n",
    "    # ì£¼ì œì— \"ì¶”ì²œìš”ì²­\"ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°\n",
    "    elif \"ì¶”ì²œìš”ì²­\" in info[\"topic\"].lower():\n",
    "        return recommend_chain\n",
    "    # ì¼ë°˜ëŒ€í™”í™”\n",
    "    else:\n",
    "        return general_chain\n",
    "    \n",
    "# from operator import itemgetter\n",
    "# from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# branch = RunnableBranch(\n",
    "#     (lambda x: \"ì •ë³´ê²€ìƒ‰\" in x[\"topic\"].lower(), info_chain),\n",
    "#     (lambda x: \"ì¶”ì²œìš”ì²­\" in x[\"topic\"].lower(), recommend_chain),\n",
    "#     general_chain,\n",
    "# )\n",
    "# full_chain = (\n",
    "#     {\"topic\": rag_chain, \"question\": itemgetter(\"question\")} | branch | StrOutputParser()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    {\"topic\": rag_chain, \"question\": itemgetter(\"question\")}\n",
    "    | RunnableLambda(\n",
    "        route\n",
    "    )\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mí•œíš¨ì£¼\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "retriever.invoke(\"í•œíš¨ì£¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_chain.invoke({\"question\": \"í•œíš¨ì£¼ê°€ ë‚˜ì˜¤ëŠ” ë“œë¼ë§ˆ ì•Œë ¤ì¤˜.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(classification_result: dict):\n",
    "    # ì‚¬ìš©ìì˜ ì…ë ¥ ìœ í˜• ë¶„ë¥˜\n",
    "    print(classification_result)\n",
    "    classification_data = classification_result.get(\"classification_result\", {})  # ë‚´ë¶€ ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ\n",
    "    type_value = classification_data.get(\"type\", \"ì¼ë°˜ëŒ€í™”\")  # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "    keywords = classification_data.get(\"keywords\", [])  # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "    \n",
    "    print(f\"===================== Type: {type_value}\")\n",
    "    print(f\"===================== Keywords: {keywords}\")\n",
    "\n",
    "    if type_value == 'ì •ë³´ê²€ìƒ‰':\n",
    "        return info_chain.invoke(str(classification_result))\n",
    "    elif type_value == 'ì¶”ì²œìš”ì²­':\n",
    "        return \"ì¶”ì²œìš”ì²­ ì²´ì¸ ì‹¤í–‰ì€ ì—¬ê¸°!!\"\n",
    "    else:\n",
    "        return default_chain.invoke({\"classification_result\": classification_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "  {\"classification_result\": RunnableLambda(preprocess_classification_result),# type keyword: dic\n",
    "   \"question\":itemgetter(\"question\")}\n",
    "  | RunnableLambda(process_user_input)\n",
    "  | StrOutputParser()  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification_result': {'type': 'ì¼ë°˜ëŒ€í™”', 'keywords': ['ì‹¬ì‹¬']}, 'question': 'ì‹¬ì‹¬'}\n",
      "===================== Type: ì¼ë°˜ëŒ€í™”\n",
      "===================== Keywords: ['ì‹¬ì‹¬']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ¶: ë©ë©!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":\"ì‹¬ì‹¬\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì •ì‚¬í•­..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgdxteam2-aSyY5fLw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
